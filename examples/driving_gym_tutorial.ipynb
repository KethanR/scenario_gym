{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e762d3",
   "metadata": {},
   "source": [
    "# Intelligent agents in Scenario Gym\n",
    "This notebook covers the process of creating custom intelligent agents in Scenario Gym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c343ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import Output, GridspecLayout\n",
    "from IPython import display\n",
    "\n",
    "import scenario_gym\n",
    "scenario_base_path = os.path.join(\"../tests/input_files/Scenarios\")\n",
    "paths = [\n",
    "    os.path.join(scenario_base_path, f)\\\n",
    "    for f in os.listdir(scenario_base_path) if \"xosc\" in f\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed47eec",
   "metadata": {},
   "source": [
    "## Toolchain Pipeline\n",
    "\n",
    "1. Load and inspect a scenario\n",
    "2. Inspect road network and available layers\n",
    "3. Setup parameters\n",
    "4. Create and add agents\n",
    "5. Define and add metrics\n",
    "6. Scenario rollout\n",
    "7. View results\n",
    "8. Run scenarios in bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b6376",
   "metadata": {},
   "source": [
    "## Scenarios\n",
    "The Scenario Gym runs scenarios from OpenScenario files. These are loaded to a `Scenario` object which can be accessed via the global state e.g. `gym.state.scenario`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4de55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym = scenario_gym.ScenarioGym()\n",
    "scenario_path = paths[0]\n",
    "gym.load_scenario(scenario_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535b075",
   "metadata": {},
   "source": [
    "The scenario consists of a list of entities and a road network. We can see a summary of the contents of our specific scenario with `scenario.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0db685",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.state.scenario.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de54db",
   "metadata": {},
   "source": [
    "Alternatively we can plot the scenario with `scenario.plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1475abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.state.scenario.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83e8db",
   "metadata": {},
   "source": [
    "Specific entity or road network data can be accessed via the individual objects. For example the road network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8a57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_filepath = gym.state.scenario.road_network.path\n",
    "road_network = scenario_gym.RoadNetwork.create_from_json(rn_filepath)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# plot the driveable surface\n",
    "for geom in road_network.driveable_surface.geoms:\n",
    "    plt.fill(*geom.exterior.xy, c='gray', alpha=0.5)\n",
    "    for i in geom.interiors:\n",
    "        plt.fill(*i.xy, c='white')\n",
    "        \n",
    "# plot the lane centers\n",
    "for x in road_network.roads + road_network.intersections:\n",
    "    for l in x.lanes:\n",
    "        plt.plot(*l.center.xy, c='b')\n",
    "    \n",
    "plt.xlim(350, 600)\n",
    "plt.ylim(400, 650)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b044958",
   "metadata": {},
   "source": [
    "## Gym setup\n",
    "To setup our environment in the way we want there are a various settings available in the gym that can be configured (before implementing agents). This section covers these parameters.\n",
    "\n",
    "### Timestep\n",
    "At each step the Scenario Gym increments the current time by a fixed amount (`gym.timestep`) and updates positions for all entities. This should be set to the desired level to balance computation and precision. Too low a value will mean many more steps per scenario and too high a value will lead to inaccurate simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8242a4e",
   "metadata": {},
   "source": [
    "### Terminal conditions\n",
    "We will want to define when our scenario is considered to have finished. We can configure this with the `terminal_conditions` parameter.\n",
    "\n",
    "Terminal conditions determine when the scenario has finished and are stored as part of the state: `state.terminal_conditions`. A state may have multiple conditions and is considered terminal when any of them are met. For example we may end the scenario when a collision occurs or if we reach a time limit. By default the scenario will end when the maximum time from its OpenScenario file is reached.\n",
    "\n",
    "These are implemented as simple callables taking the state as argument and returning a boolean. As an example below is condition that ends the scenario after a minute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_after_a_minute(state):\n",
    "    return state.t > 60."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2974f99",
   "metadata": {},
   "source": [
    "Some common conditions are provided and can be used by supplying their string identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4f48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym.state import TERMINAL_CONDITIONS\n",
    "list(TERMINAL_CONDITIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a0ec0",
   "metadata": {},
   "source": [
    "* `max_length` ends when the maximum time from the OpenScenario is reached. This is the default condition.\n",
    "* `collision` ends if there is a collision between any two entities.\n",
    "* `ego_collision` ends if there is a collision between the ego and another entity.\n",
    "* `ego_off_road` ends when the ego leaves the `driveable_surface` layer of the road network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59f120",
   "metadata": {},
   "source": [
    "### Rendering and recording\n",
    "The Scenario Gym can render scenarios as videos and record them to OpenScenario files. To run a scenario once it is loaded with the requried settings we call `gym.rollout()`.\n",
    "\n",
    "We can render the scenario as a video by passing `render=True` to rollout. By default this will look for a recordings folder at the same level as the scenario's directory but we can give it a custom path by passing `video_path=...` to rollout. There are several parameters that control the rendering which can be seen in `scenario_gym.viewer.Viewer`.\n",
    "\n",
    "To record a scenario we pass `record=True` to rollout. The gym will then log the pose of each entity after every timestep. Once the scenario is finished we can generate an OpenScenario file by `gym.recorder.write_xosc(output_path)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2958a8",
   "metadata": {},
   "source": [
    "## Agents, sensors and controllers\n",
    "Agents are implemented in the Scenario Gym through three modules: `Sensor`, `Agent` and `Controller`. These manage the process for generating the observation, producing the action and updating the entity state:\n",
    "* the `Sensor` produces an `Observation` from the `State`,\n",
    "* the `Agent` recieves the observation and returns an `Action`,\n",
    "* the `Controller` updates the agent's pose and internal state from the action.\n",
    "The interface of each object requires a `_reset` and `_step` method to be implemented. The `_reset` method resets the internal state of each object at the start of a scenario. The `_step` method implements each object's part of the process.\n",
    "\n",
    "### Sensors\n",
    "The sensor module produces observations from the state. It takes the full global state as input and produces the local information which is available to the agent. \n",
    "\n",
    "An example sensor already implemeted in the Scenario Gym is the `RasterizedMapSensor` which returns an observation in the form of an array representation of the area around the agent with shape `(width, height, layers)`. The layers are semantic layers of the scene such as the driveable surface or the bounding boxes of nearby entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed19920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym.sensor import RasterizedMapSensor\n",
    "sensor = RasterizedMapSensor(\n",
    "    gym.state.scenario.entities[0],\n",
    "    layers=[\"entity\", \"driveable_surface\"],\n",
    "    height=20.,\n",
    "    width=20.,\n",
    "    freq=10,\n",
    ")\n",
    "print(f\"Rasterized map shape: {sensor.output_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c36d13",
   "metadata": {},
   "source": [
    "This sensor has two layers. Here is what it produces at `t = 9` in the current scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.reset_scenario()\n",
    "for _ in range(30 * 9):\n",
    "    gym.step()\n",
    "sensor.reset()\n",
    "observation = sensor._step(gym.state)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(7, 5), ncols=2)\n",
    "ax[0].imshow(np.flip(observation[...,0]), cmap='Blues')\n",
    "ax[1].imshow(np.flip(observation[...,1]), cmap='Blues')\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[0].title.set_text(\"Entity layer\")\n",
    "ax[1].title.set_text(\"Driveable surface layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a802d",
   "metadata": {},
   "source": [
    "### Custom Sensors\n",
    "To implement a custom sensor we implement the `_reset` and `_step` methods. The output produced by the sensor should be local to the entity it represents. The sensor can access its entity at any time via `sensor.entity`. From this it can access for example the position or velocity of its entity: `sensor.entity.pose`, `sensor.entity.velocity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bd2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym import Entity, State, Observation, Sensor\n",
    "\n",
    "class CustomSensor(Sensor):\n",
    "\n",
    "    def __init__(self, entity: Entity):\n",
    "        \"\"\"\n",
    "        Assign any fixed parameters here.\n",
    "        \"\"\"\n",
    "        super().__init__(entity)\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Reset any scenario dependent parameters here.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _step(self, state: State) -> Observation:\n",
    "        \"\"\"\n",
    "        Generate the observation for the entity from the global state here.\n",
    "        \"\"\"\n",
    "        observation = ...\n",
    "        return observation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50f42d",
   "metadata": {},
   "source": [
    "As an example, the sensor below will detect entities within a distance ahead of the ego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbe3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "from typing import List\n",
    "\n",
    "class ForwardSesnor(Sensor):\n",
    "    \"\"\"Detects entities a distance ahead of the entity.\"\"\"\n",
    "    \n",
    "    def __init__(self, entity: Entity, distance: float = 10.):\n",
    "        super().__init__(entity)\n",
    "        self.distance = distance\n",
    "    \n",
    "    def _reset(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def _step(self, state: State) -> List[Entity]:\n",
    "        # get a vector in the direction of the entity's heading\n",
    "        h = self.entity.pose[3]\n",
    "        vec = np.array([np.cos(h), np.sin(h)])\n",
    "        \n",
    "        # get a Polygon covering the area\n",
    "        area = LineString([\n",
    "            self.entity.pose[:2],\n",
    "            self.entity.pose[:2] + vec * self.distance,\n",
    "        ]).buffer(2.)\n",
    "        \n",
    "        # return any other entities within that area\n",
    "        ents = state.scenario.get_entities_in_area(area)\n",
    "        return [e for e in ents if e != self.entity]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba1b5f",
   "metadata": {},
   "source": [
    "### Controllers\n",
    "The controller processes the agent's action to update the global state. It is responsible for managing the physical model of the entity and updating it after the agent's action. For example, our agent may produce vehicle actions such as a steering velocity and an acceleration which we decode via a kinematic model to update the entity's position.\n",
    "\n",
    "The Scenario Gym package includes a several vehicle controllers:\n",
    "* `VehicleController`: uses a physical model to control the motion of a vehicle and respond to vehicle actions (accerlation and steering).\n",
    "* `BasicVehicleController`: controls a vehicle with very simple dynamics and minimal physical constraints.\n",
    "* `PIDController`: uses PID control and a vehicle model to follow waypoint actions.\n",
    "\n",
    "### Custom controllers\n",
    "We implement controllers in a similar manner to the sensor. The controller will take the state and action and should update its internal state and return the new pose for the entity. After all the gym has gathered the new poses for all entities it will update the global state for advance the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be93af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym import Entity, Controller, State, Action\n",
    "\n",
    "class CustomController(Controller):\n",
    "\n",
    "    def __init__(self, entity: Entity):\n",
    "        \"\"\"\n",
    "        Assign any fixed parameters here.\n",
    "        \"\"\"\n",
    "        super().__init__(entity)\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Reset any scenario dependent parameters here.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _step(self, state: State, action: Action) -> \"Pose\":\n",
    "        \"\"\"\n",
    "        Update the controller internal state and return the next pose.\n",
    "        \"\"\"\n",
    "        next_pose = ...\n",
    "        return next_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c4c18",
   "metadata": {},
   "source": [
    "### Agents\n",
    "An agent controls a single entity. It has a sensor to provide local observations from which the agent selects an action and a controller which process the action to update the entity's position. Each agent stores the reference to its sensor and controller so are constructed as:\n",
    "\n",
    "`agent = Agent(entity, sensor, controller)`.\n",
    "\n",
    "The `_step` must be implemented for each agent and will produce the chosen action from each observation. The `step` method of the agent will then handle the calls to each module:\n",
    "```python\n",
    "class Agent:\n",
    "    ...\n",
    "    def step(self, state):\n",
    "        obs = self.sensor.step(state)\n",
    "        action = self._step(state, obs)\n",
    "        next_pose = self.controller.step(state, action)\n",
    "        return next_pose\n",
    "```\n",
    "Along with the `_step` method, each agent must also implement `_reset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eacdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym import Agent, Action, Controller, Entity, Observation, Sensor, State\n",
    "\n",
    "class CustomAgent(Agent):\n",
    "\n",
    "    def __init__(self, entity: Entity, controller: Controller, sensor: Sensor):\n",
    "        \"\"\"\n",
    "        Assign any fixed parameters here.\n",
    "        \"\"\"\n",
    "        super().__init__(entity, controller, sensor)\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        \"\"\"\n",
    "        Reset any scenario dependent parameters here.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _step(self, state: State, observation: Observation) -> Action:\n",
    "        \"\"\"\n",
    "        Select an action from the observation.\n",
    "        \"\"\"\n",
    "        action = ...\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd638812",
   "metadata": {},
   "source": [
    "When implementing agents we must decide the sensor and controller that they will use which will determine their observation and action spaces. Then we implement the `_step` method. Since we pass the sensor and controller to the agent's constructor we can define them in the constructor of our subclass. For example, below shows a vehicle agent that takes a rasterized map representation as observation, selects acceleration and steering values via a neural network and then passes these to a vehicle controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a17c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from scenario_gym.action import VehicleAction\n",
    "from scenario_gym.controller import VehicleController\n",
    "from scenario_gym.sensor import RasterizedMapSensor\n",
    "\n",
    "class NeuralAgent(Agent):\n",
    "    \"\"\"An agent controlled by a given neural network.\"\"\"\n",
    "    \n",
    "    def __init__(self, entity: Entity, network: nn.Module):\n",
    "        self.network = network\n",
    "        controller = VehicleController(entity)\n",
    "        sensor = RasterizedMapSensor(entity)\n",
    "        super().__init__(\n",
    "            entity,\n",
    "            controller,\n",
    "            sensor,\n",
    "        )\n",
    "    \n",
    "    def _reset(self):\n",
    "        pass\n",
    "    \n",
    "    def _step(self, state, observation):\n",
    "        observation = torch.from_numpy(observation)\n",
    "        with torch.no_grad():\n",
    "            output = self.network(observation)\n",
    "        accel, steer = output.numpy()\n",
    "        return VehicleAction(accel, steer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1883c20",
   "metadata": {},
   "source": [
    "### Short note on Actions and Observations\n",
    "The scenario_gym package defines the types `Action` and `Observation`. These are trivial classes so it is not strictly necessary to subclass them. However, it is helpful for type hints and can provide a common format for some frequently used actions. The pacakge defines a couple of standard actions:\n",
    "* `TeleportAction`: a specific pose or position,\n",
    "* `VehicleAction`: a steering and acceleration,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb47da50",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "When running scenarios we will want to measure different quantities and look out for various events. We can do this with the `Metric` object. This implements the `step` and `reset` methods similarly to the agent. The step method is called after every timestep for the metric to update its internal state e.g. to update a running mean. After the scenario we call `metric.get_state()` to return the metric's value and then `metric.reset()` to prepare for the next scenario.\n",
    "\n",
    "To define a metric we implement `_reset`, `_step` and `get_state`. Then we add the metric to the gym before running any scenarios. We should remember to call `metric.get_state` after the scenario has finished and record the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b212a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym.metrics import Metric\n",
    "class EgoSpeedMetric(Metric):\n",
    "    \"\"\"Compute the average speed of the ego.\"\"\"\n",
    "    \n",
    "    def _reset(self, state):\n",
    "        self.ds = 0.\n",
    "        self.t = 0.\n",
    "    \n",
    "    def _step(self, state):\n",
    "        ego = state.scenario.entities[0]\n",
    "        self.ds += np.linalg.norm(ego.velocity[:2]) * ego.dt\n",
    "        self.t = ego.t\n",
    "        \n",
    "    def get_state(self):\n",
    "        return self.ds / self.t if self.t > 0 else 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63437ce4",
   "metadata": {},
   "source": [
    "We can then add the metric to the gym and rollout the scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = EgoSpeedMetric()\n",
    "gym = scenario_gym.ScenarioGym(metrics=[metric])\n",
    "gym.load_scenario(paths[0])\n",
    "gym.rollout()\n",
    "result = metric.get_state()\n",
    "print(f\"Ego average speed: {result:.4}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc6293",
   "metadata": {},
   "source": [
    "## Scenario rollouts\n",
    "Once we have implemented our intelligent agents and defined our metrics we are ready to run scenarios. Before running we need to assign agents to the relevant entities. This is important since This is done by defining a function to create an agent for any given entity which will be called for each entity in the scenario. This function should have the signature: `(scenario, entity) -> Optional[Agent]`. The output can be `None` since we do not have to assign an agent to each entity. If we don't then the entity will follow its predefined trajectory.\n",
    "\n",
    "We pass our function when loading the scenario to the gym: \n",
    "```python\n",
    "def create_agent(s, e) -> Optional[Agent]:\n",
    "    ...\n",
    "    \n",
    "gym.load_scenario(filepath, create_agent=create_agent)\n",
    "```\n",
    "To determine the correct agent to use for each entity we can use entity characteristics e.g. the type or category, or the unique reference (`e.ref`). After this we can rollout the scenario. For example we could assign the neural agent to the ego, another to all pedestrians and leave all other entities:\n",
    "```python\n",
    "def create_agent(scenario: Scenario, entity: Entity) -> Optional[Agent]:\n",
    "    \"\"\"\"\"\"\n",
    "    if entity.ref == \"ego\":\n",
    "        return NeuralAgent(...)\n",
    "    elif entity.type == \"Pedestrian\":\n",
    "        return PedestrianAgent(...)\n",
    "``` \n",
    "We can inspect our agents after we have loaded the scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17eddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.state.scenario.agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c25d9a",
   "metadata": {},
   "source": [
    "Now we can rollout the scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc8d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.rollout(render=True, video_path=os.path.join(GYM_PATH, \"examples/example1.mp4\"))\n",
    "display.Video(os.path.join(GYM_PATH, \"examples/example1.mp4\"), embed=True, width=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31e622",
   "metadata": {},
   "source": [
    "We can change the rendering behaviour by modifying the `viewer_parameters`. For example to display all road and lane centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.viewer_parameters[\"render_layers\"] = [\"driveable_surface\", \"centers\"]\n",
    "gym.rollout(render=True, video_path=os.path.join(GYM_PATH, \"examples/example2.mp4\"))\n",
    "display.Video(os.path.join(GYM_PATH, \"examples/example2.mp4\"), embed=True, width=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de583605",
   "metadata": {},
   "source": [
    "All renderable layers can be seen in `Viewer._renderable_layers`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f41ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_gym.viewer.Viewer._renderable_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b3c9c",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "### State callbacks\n",
    "Often when creating intelligent agents we will need to derive are provide extra data from the global state that is not included in the scenario by default. For example we may want to simulate a scene with traffic signals which are not provided in the OpenScenario file. We could incorporate this when we implement our agent e.g. via its sensor module however if we have many agents which all need access to this information this may not be efficient. An alternative is to use the `state_callbacks` parameter of the Scenario Gym. This takes callables which take the state as input and modify it inplace. These are called every step to provide additional information without repeating computation. For example below we provide an additional parameter to the state giving the colour of a traffic light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2bb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic_light_callback(state):\n",
    "    t = state.t % 60. \n",
    "    if t < 20.:\n",
    "        state.traffic_light_colour = \"Green\"\n",
    "    elif t < 30.:\n",
    "        state.traffic_light_colour = \"Yellow\"\n",
    "    else:\n",
    "        state.traffic_light_colour = \"Red\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a952fb",
   "metadata": {},
   "source": [
    "This is passed to the Scenario Gym constructor and then will be called whenever the timestamp is updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047605bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym = scenario_gym.ScenarioGym(state_callbacks=[traffic_light_callback])\n",
    "gym.load_scenario(paths[0])\n",
    "gym.rollout()\n",
    "print(f\"Current light colour: {gym.state.traffic_light_colour}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d664ff",
   "metadata": {},
   "source": [
    "### Running scenarios in bulk with the scenario manager\n",
    "To better manage running scenarios in bulk we can use the `ScenarioManager` class. This class will help us store all of the parameters and metrics and run multiple scenarios. We just overwrite the `create_agent` method of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bf9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym.manager import ScenarioManager\n",
    "from scenario_gym.agent import ReplayTrajectoryAgent\n",
    "\n",
    "class Manager(ScenarioManager):\n",
    "    \n",
    "    def create_agent(self, scenario, entity):\n",
    "        if entity.ref == \"ego\":\n",
    "            return ReplayTrajectoryAgent(\n",
    "                entity,\n",
    "                scenario_gym.controller.ReplayTrajectoryController(entity),\n",
    "                scenario_gym.sensor.EgoLocalizationSensor(entity),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fac66",
   "metadata": {},
   "source": [
    "When we initialize the scenario manager we pass any gym or rendering parameters and any additional custom parameters. Then we can add any metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d47ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = Manager(timestep=0.1, custom_parameter=2.)\n",
    "\n",
    "manager.add_metric(EgoSpeedMetric())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd25148",
   "metadata": {},
   "source": [
    "Then we can run scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeba2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = manager.run_scenarios(paths[:5])\n",
    "print(f\"Ego average speed across scenarios: {np.mean(results):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bba5af",
   "metadata": {},
   "source": [
    "### Custom scenarios\n",
    "In some cases we may want to modify the scenarios before running them through the gym or to create new ones entirely. We do this by either loading the scenario from OpenScenario or creating it and then using the `gym._set_scenario` method to attach it to the gym.\n",
    "\n",
    "If we wish to edit an existing scenario then we can load it from apply modifications to it after loading it via `gym.load_scenario`. For example we could vary the timing of an entity's trajectory. Here we add 1 second to each control point of the second entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym.xosc_interface import import_scenario\n",
    "gym = scenario_gym.ScenarioGym()\n",
    "\n",
    "scenario = import_scenario(paths[0])\n",
    "\n",
    "entity = scenario.entities[1]\n",
    "entity.trajectory.data[:,0] += 1.\n",
    "\n",
    "gym._set_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07df91a",
   "metadata": {},
   "source": [
    "We can also create a scenario programatically. We just need to load the required components e.g. catalog information and road networks and then define trajectories. Below we create a trajectory with a single entity moving along the y-axis. We could also have created our entity by defining a custom catalog entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94490178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scenario_gym.xosc_interface import read_catalog\n",
    "from scenario_gym.scenario import Scenario\n",
    "from scenario_gym.trajectory import Trajectory\n",
    "from scenario_gym.road_network import RoadNetwork\n",
    "from copy import deepcopy\n",
    "\n",
    "# create a scenario\n",
    "scenario = Scenario()\n",
    "\n",
    "# load a road network\n",
    "scenario.road_network = RoadNetwork.create_from_json(\n",
    "    \"../tests/input_files/Road_Networks/Greenwich_Road_Network_002.json\"\n",
    ")\n",
    "\n",
    "# create a bcar1` entity\n",
    "_, catalogs = read_catalog(\"../tests/input_files/Catalogs/VehicleCatalogs/ScenarioGymVehicleCatalog.xosc\")\n",
    "e = deepcopy(catalogs[\"car1\"])\n",
    "e.ref = \"ego\"\n",
    "\n",
    "# define its trajectory\n",
    "e.trajectory = Trajectory(\n",
    "    np.array([\n",
    "        [1., 0., 1.],\n",
    "        [2., 0., 2.],\n",
    "        [3., 0., 3.],\n",
    "    ]),\n",
    "    fields=[\"t\", \"x\", \"y\"],\n",
    ")\n",
    "\n",
    "# add the entity\n",
    "scenario.entities.append(e)\n",
    "\n",
    "gym._set_scenario(scenario)\n",
    "gym.rollout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
